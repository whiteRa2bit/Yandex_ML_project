{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# To make sure our kernel runs all the way through and gets saved,\n",
    "# we'll trim some things back and skip training\n",
    "IS_KAGGLE = True \n",
    "\n",
    "CMU_DICT_PATH = \"/home/pavel/MyDocs/MachineLearning/Yandex_ML_project/lecture4/Kaggle_phonetics/model_example/cmudict-0.7b\"\n",
    "\n",
    "CMU_SYMBOLS_PATH = \"/home/pavel/MyDocs/MachineLearning/Yandex_ML_project/lecture4/Kaggle_phonetics/model_example/cmudict.symbols\"\n",
    "\n",
    "# Skip words with numbers or symbols\n",
    "ILLEGAL_CHAR_REGEX = \"[^A-Z-'.]\"\n",
    "\n",
    "# Only 3 words are longer than 20 chars\n",
    "# Setting a limit now simplifies training our model later\n",
    "MAX_DICT_WORD_LEN = 20\n",
    "MIN_DICT_WORD_LEN = 2\n",
    "\n",
    "\n",
    "def load_clean_phonetic_dictionary():\n",
    "\n",
    "    def is_alternate_pho_spelling(word):\n",
    "        # No word has > 9 alternate pronounciations so this is safe\n",
    "        return word[-1] == ')' and word[-3] == '(' and word[-2].isdigit() \n",
    "\n",
    "    def should_skip(word):\n",
    "        if not word[0].isalpha():  # skip symbols\n",
    "            return True\n",
    "        if word[-1] == '.':  # skip abbreviations\n",
    "            return True\n",
    "        if re.search(ILLEGAL_CHAR_REGEX, word):\n",
    "            return True\n",
    "        if len(word) > MAX_DICT_WORD_LEN:\n",
    "            return True\n",
    "        if len(word) < MIN_DICT_WORD_LEN:\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    phonetic_dict = {}\n",
    "    with open(CMU_DICT_PATH, encoding=\"ISO-8859-1\") as cmu_dict:\n",
    "        for line in cmu_dict:\n",
    "\n",
    "            # Skip commented lines\n",
    "            if line[0:3] == ';;;':\n",
    "                continue\n",
    "\n",
    "            word, phonetic = line.strip().split('  ')\n",
    "\n",
    "            # Alternate pronounciations are formatted: \"WORD(#)  F AH0 N EH1 T IH0 K\"\n",
    "            # We don't want to the \"(#)\" considered as part of the word\n",
    "            if is_alternate_pho_spelling(word):\n",
    "                word = word[:word.find('(')]\n",
    "\n",
    "            if should_skip(word):\n",
    "                continue\n",
    "\n",
    "            if word not in phonetic_dict:\n",
    "                phonetic_dict[word] = []\n",
    "            phonetic_dict[word].append(phonetic)\n",
    "\n",
    "    if IS_KAGGLE: # limit dataset to 5,000 words\n",
    "        phonetic_dict = {key:phonetic_dict[key] \n",
    "                         for key in random.sample(list(phonetic_dict.keys()), 5000)}\n",
    "    return phonetic_dict\n",
    "\n",
    "phonetic_dict = load_clean_phonetic_dictionary()\n",
    "example_count = np.sum([len(prons) for _, prons in phonetic_dict.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BECKONS --> B EH1 K AH0 N Z\n",
      "RAZO --> R AA1 Z OW0\n",
      "STENY --> S T EH1 N IY0\n",
      "MOBLEY --> M OW1 B L IY0\n",
      "FOISTED --> F OY1 S T IH0 D\n",
      "FREQUENCIES --> F R IY1 K W AH0 N S IY0 Z\n",
      "AMERICARE --> AH0 M EH1 R IH0 K EH2 R\n",
      "SOLERI --> S OW0 L EH1 R IY0\n",
      "KICKOFF --> K IH1 K AO2 F\n",
      "TANGLE --> T AE1 NG G AH0 L\n",
      "\n",
      "After cleaning, the dictionary contains 5000 words and 5304 pronunciations (304 are alternate pronunciations).\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join([k+' --> '+phonetic_dict[k][0] for k in random.sample(list(phonetic_dict.keys()), 10)]))\n",
    "print('\\nAfter cleaning, the dictionary contains %s words and %s pronunciations (%s are alternate pronunciations).' % \n",
    "      (len(phonetic_dict), example_count, (example_count-len(phonetic_dict))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['F ER1 Z'], ['K AA1 N T R AE0 S T S', 'K AH0 N T R AE1 S T S'], ['M AY1 D IH0 NG ER0'], ['N AA2 N P R AH0 D AH1 K T IH0 V'], ['D R EH1 S AH0 N'], ['P AE1 N Z'], ['D AH1 G AW2 T'], ['L IH1 N L IY0'], ['IH2 M P AA1 V R IH0 SH'], ['HH AA1 P M AH0 N']]\n"
     ]
    }
   ],
   "source": [
    "print(list(phonetic_dict.values())[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Char to id mapping: \n",
      " {'': 0, '.': 1, '-': 2, \"'\": 3, 'A': 4, 'B': 5, 'C': 6, 'D': 7, 'E': 8, 'F': 9, 'G': 10, 'H': 11, 'I': 12, 'J': 13, 'K': 14, 'L': 15, 'M': 16, 'N': 17, 'O': 18, 'P': 19, 'Q': 20, 'R': 21, 'S': 22, 'T': 23, 'U': 24, 'V': 25, 'W': 26, 'X': 27, 'Y': 28, 'Z': 29}\n",
      "Phone to id mapping: \n",
      " {'': 0, '\\t': 1, '\\n': 2, 'AA': 3, 'AA0': 4, 'AA1': 5, 'AA2': 6, 'AE': 7, 'AE0': 8, 'AE1': 9, 'AE2': 10, 'AH': 11, 'AH0': 12, 'AH1': 13, 'AH2': 14, 'AO': 15, 'AO0': 16, 'AO1': 17, 'AO2': 18, 'AW': 19, 'AW0': 20, 'AW1': 21, 'AW2': 22, 'AY': 23, 'AY0': 24, 'AY1': 25, 'AY2': 26, 'B': 27, 'CH': 28, 'D': 29, 'DH': 30, 'EH': 31, 'EH0': 32, 'EH1': 33, 'EH2': 34, 'ER': 35, 'ER0': 36, 'ER1': 37, 'ER2': 38, 'EY': 39, 'EY0': 40, 'EY1': 41, 'EY2': 42, 'F': 43, 'G': 44, 'HH': 45, 'IH': 46, 'IH0': 47, 'IH1': 48, 'IH2': 49, 'IY': 50, 'IY0': 51, 'IY1': 52, 'IY2': 53, 'JH': 54, 'K': 55, 'L': 56, 'M': 57, 'N': 58, 'NG': 59, 'OW': 60, 'OW0': 61, 'OW1': 62, 'OW2': 63, 'OY': 64, 'OY0': 65, 'OY1': 66, 'OY2': 67, 'P': 68, 'R': 69, 'S': 70, 'SH': 71, 'T': 72, 'TH': 73, 'UH': 74, 'UH0': 75, 'UH1': 76, 'UH2': 77, 'UW': 78, 'UW0': 79, 'UW1': 80, 'UW2': 81, 'V': 82, 'W': 83, 'Y': 84, 'Z': 85, 'ZH': 86}\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "START_PHONE_SYM = '\\t'\n",
    "END_PHONE_SYM = '\\n'\n",
    "\n",
    "\n",
    "def char_list():\n",
    "    allowed_symbols = [\".\", \"-\", \"'\"]\n",
    "    uppercase_letters = list(string.ascii_uppercase)\n",
    "    return [''] + allowed_symbols + uppercase_letters\n",
    "\n",
    "\n",
    "def phone_list():\n",
    "    phone_list = [START_PHONE_SYM, END_PHONE_SYM]\n",
    "    with open(CMU_SYMBOLS_PATH) as file:\n",
    "        for line in file: \n",
    "            phone_list.append(line.strip())\n",
    "    return [''] + phone_list\n",
    "\n",
    "\n",
    "def id_mappings_from_list(str_list):\n",
    "    str_to_id = {s: i for i, s in enumerate(str_list)} \n",
    "    id_to_str = {i: s for i, s in enumerate(str_list)}\n",
    "    return str_to_id, id_to_str\n",
    "\n",
    "\n",
    "# Create character to ID mappings\n",
    "char_to_id, id_to_char = id_mappings_from_list(char_list())\n",
    "\n",
    "# Load phonetic symbols and create ID mappings\n",
    "phone_to_id, id_to_phone = id_mappings_from_list(phone_list())\n",
    "\n",
    "# Example:\n",
    "print('Char to id mapping: \\n', char_to_id)\n",
    "print('Phone to id mapping: \\n', phone_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A\" is represented by:\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.] \n",
      "-----\n",
      "\"AH0\" is represented by:\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "CHAR_TOKEN_COUNT = len(char_to_id)\n",
    "PHONE_TOKEN_COUNT = len(phone_to_id)\n",
    "\n",
    "\n",
    "def char_to_1_hot(char):\n",
    "    char_id = char_to_id[char]\n",
    "    hot_vec = np.zeros((CHAR_TOKEN_COUNT))\n",
    "    hot_vec[char_id] = 1.\n",
    "    return hot_vec\n",
    "\n",
    "\n",
    "def phone_to_1_hot(phone):\n",
    "    phone_id = phone_to_id[phone]\n",
    "    hot_vec = np.zeros((PHONE_TOKEN_COUNT))\n",
    "    hot_vec[phone_id] = 1.\n",
    "    return hot_vec\n",
    "\n",
    "# Example:\n",
    "print('\"A\" is represented by:\\n', char_to_1_hot('A'), '\\n-----')\n",
    "print('\"AH0\" is represented by:\\n', phone_to_1_hot('AH0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Matrix Shape:  (5304, 18, 30)\n",
      "Pronunciation Matrix Shape:  (5304, 19, 87)\n"
     ]
    }
   ],
   "source": [
    "MAX_CHAR_SEQ_LEN = max([len(word) for word, _ in phonetic_dict.items()])\n",
    "MAX_PHONE_SEQ_LEN = max([max([len(pron.split()) for pron in pronuns]) \n",
    "                         for _, pronuns in phonetic_dict.items()]\n",
    "                       ) + 2  # + 2 to account for the start & end tokens we need to add\n",
    "\n",
    "\n",
    "def dataset_to_1_hot_tensors():\n",
    "    char_seqs = []\n",
    "    phone_seqs = []\n",
    "    \n",
    "    for word, pronuns in phonetic_dict.items():\n",
    "        word_matrix = np.zeros((MAX_CHAR_SEQ_LEN, CHAR_TOKEN_COUNT))\n",
    "        for t, char in enumerate(word):\n",
    "            word_matrix[t, :] = char_to_1_hot(char)\n",
    "        for pronun in pronuns:\n",
    "            pronun_matrix = np.zeros((MAX_PHONE_SEQ_LEN, PHONE_TOKEN_COUNT))\n",
    "            phones = [START_PHONE_SYM] + pronun.split() + [END_PHONE_SYM]\n",
    "            for t, phone in enumerate(phones):\n",
    "                pronun_matrix[t,:] = phone_to_1_hot(phone)\n",
    "                \n",
    "            char_seqs.append(word_matrix)\n",
    "            phone_seqs.append(pronun_matrix)\n",
    "    \n",
    "    return np.array(char_seqs), np.array(phone_seqs)\n",
    "            \n",
    "\n",
    "char_seq_matrix, phone_seq_matrix = dataset_to_1_hot_tensors()        \n",
    "print('Word Matrix Shape: ', char_seq_matrix.shape)\n",
    "print('Pronunciation Matrix Shape: ', phone_seq_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "phone_seq_matrix_decoder_output = np.pad(phone_seq_matrix,((0,0),(0,1),(0,0)), mode='constant')[:,1:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "\n",
    "def baseline_model(hidden_nodes = 256):\n",
    "    \n",
    "    # Shared Components - Encoder\n",
    "    char_inputs = Input(shape=(None, CHAR_TOKEN_COUNT))\n",
    "    encoder = LSTM(hidden_nodes, return_state=True)\n",
    "    \n",
    "    # Shared Components - Decoder\n",
    "    phone_inputs = Input(shape=(None, PHONE_TOKEN_COUNT))\n",
    "    decoder = LSTM(hidden_nodes, return_sequences=True, return_state=True)\n",
    "    decoder_dense = Dense(PHONE_TOKEN_COUNT, activation='softmax')\n",
    "    \n",
    "    # Training Model\n",
    "    _, state_h, state_c = encoder(char_inputs) # notice encoder outputs are ignored\n",
    "    encoder_states = [state_h, state_c]\n",
    "    decoder_outputs, _, _ = decoder(phone_inputs, initial_state=encoder_states)\n",
    "    phone_prediction = decoder_dense(decoder_outputs)\n",
    "\n",
    "    training_model = Model([char_inputs, phone_inputs], phone_prediction)\n",
    "    \n",
    "    # Testing Model - Encoder\n",
    "    testing_encoder_model = Model(char_inputs, encoder_states)\n",
    "    \n",
    "    # Testing Model - Decoder\n",
    "    decoder_state_input_h = Input(shape=(hidden_nodes,))\n",
    "    decoder_state_input_c = Input(shape=(hidden_nodes,))\n",
    "    decoder_state_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "    decoder_outputs, decoder_state_h, decoder_state_c = decoder(phone_inputs, initial_state=decoder_state_inputs)\n",
    "    decoder_states = [decoder_state_h, decoder_state_c]\n",
    "    phone_prediction = decoder_dense(decoder_outputs)\n",
    "    \n",
    "    testing_decoder_model = Model([phone_inputs] + decoder_state_inputs, [phone_prediction] + decoder_states)\n",
    "    \n",
    "    return training_model, testing_encoder_model, testing_decoder_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "TEST_SIZE = 0.2\n",
    "    \n",
    "(char_input_train, char_input_test, \n",
    " phone_input_train, phone_input_test, \n",
    " phone_output_train, phone_output_test) = train_test_split(\n",
    "    char_seq_matrix, phone_seq_matrix, phone_seq_matrix_decoder_output, \n",
    "    test_size=TEST_SIZE, random_state=42)\n",
    "\n",
    "TEST_EXAMPLE_COUNT = char_input_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "def train(model, weights_path, encoder_input, decoder_input, decoder_output):\n",
    "    checkpointer = ModelCheckpoint(filepath=weights_path, verbose=1, save_best_only=True)\n",
    "    stopper = EarlyStopping(monitor='val_loss',patience=3)\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "    model.fit([encoder_input, decoder_input], decoder_output,\n",
    "          batch_size=256,\n",
    "          epochs=100,\n",
    "          validation_split=0.2, # Keras will automatically create a validation set for us\n",
    "          callbacks=[checkpointer, stopper])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3394 samples, validate on 849 samples\n",
      "Epoch 1/100\n",
      "3394/3394 [==============================] - 8s 2ms/step - loss: 1.6405 - val_loss: 1.3425\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.34253, saving model to /home/pavel/MyDocs/MachineLearning/Yandex_ML_project/lecture4/Kaggle_phonetics/baseline_model_weights.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pavel/anaconda3/envs/py36/lib/python3.6/site-packages/keras/engine/network.py:888: UserWarning: Layer lstm_10 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_9/while/Exit_2:0' shape=(?, 256) dtype=float32>, <tf.Tensor 'lstm_9/while/Exit_3:0' shape=(?, 256) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      "3394/3394 [==============================] - 6s 2ms/step - loss: 1.3313 - val_loss: 1.2780\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.34253 to 1.27796, saving model to /home/pavel/MyDocs/MachineLearning/Yandex_ML_project/lecture4/Kaggle_phonetics/baseline_model_weights.hdf5\n",
      "Epoch 3/100\n",
      "3394/3394 [==============================] - 6s 2ms/step - loss: 1.2828 - val_loss: 1.2587\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.27796 to 1.25871, saving model to /home/pavel/MyDocs/MachineLearning/Yandex_ML_project/lecture4/Kaggle_phonetics/baseline_model_weights.hdf5\n",
      "Epoch 4/100\n",
      "3394/3394 [==============================] - 6s 2ms/step - loss: 1.2682 - val_loss: 1.2464\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.25871 to 1.24639, saving model to /home/pavel/MyDocs/MachineLearning/Yandex_ML_project/lecture4/Kaggle_phonetics/baseline_model_weights.hdf5\n",
      "Epoch 5/100\n",
      "3394/3394 [==============================] - 6s 2ms/step - loss: 1.2570 - val_loss: 1.2354\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.24639 to 1.23543, saving model to /home/pavel/MyDocs/MachineLearning/Yandex_ML_project/lecture4/Kaggle_phonetics/baseline_model_weights.hdf5\n",
      "Epoch 6/100\n",
      "3394/3394 [==============================] - 6s 2ms/step - loss: 1.2458 - val_loss: 1.2219\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.23543 to 1.22191, saving model to /home/pavel/MyDocs/MachineLearning/Yandex_ML_project/lecture4/Kaggle_phonetics/baseline_model_weights.hdf5\n",
      "Epoch 7/100\n",
      "3394/3394 [==============================] - 6s 2ms/step - loss: 1.2357 - val_loss: 1.2102\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.22191 to 1.21017, saving model to /home/pavel/MyDocs/MachineLearning/Yandex_ML_project/lecture4/Kaggle_phonetics/baseline_model_weights.hdf5\n",
      "Epoch 8/100\n",
      "3394/3394 [==============================] - 6s 2ms/step - loss: 1.2241 - val_loss: 1.1976\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.21017 to 1.19763, saving model to /home/pavel/MyDocs/MachineLearning/Yandex_ML_project/lecture4/Kaggle_phonetics/baseline_model_weights.hdf5\n",
      "Epoch 9/100\n",
      "3394/3394 [==============================] - 9s 3ms/step - loss: 1.2087 - val_loss: 1.1791\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.19763 to 1.17910, saving model to /home/pavel/MyDocs/MachineLearning/Yandex_ML_project/lecture4/Kaggle_phonetics/baseline_model_weights.hdf5\n",
      "Epoch 10/100\n",
      "3394/3394 [==============================] - 8s 2ms/step - loss: 1.1912 - val_loss: 1.1633\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.17910 to 1.16325, saving model to /home/pavel/MyDocs/MachineLearning/Yandex_ML_project/lecture4/Kaggle_phonetics/baseline_model_weights.hdf5\n",
      "Epoch 11/100\n",
      "3394/3394 [==============================] - 7s 2ms/step - loss: 1.1692 - val_loss: 1.1714\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.16325\n",
      "Epoch 12/100\n",
      "3394/3394 [==============================] - 10s 3ms/step - loss: 1.1598 - val_loss: 1.1283\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.16325 to 1.12835, saving model to /home/pavel/MyDocs/MachineLearning/Yandex_ML_project/lecture4/Kaggle_phonetics/baseline_model_weights.hdf5\n",
      "Epoch 13/100\n",
      "3394/3394 [==============================] - 8s 2ms/step - loss: 1.1347 - val_loss: 1.1020\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.12835 to 1.10198, saving model to /home/pavel/MyDocs/MachineLearning/Yandex_ML_project/lecture4/Kaggle_phonetics/baseline_model_weights.hdf5\n",
      "Epoch 14/100\n",
      "3394/3394 [==============================] - 8s 2ms/step - loss: 1.1073 - val_loss: 1.0781\n",
      "\n",
      "Epoch 00014: val_loss improved from 1.10198 to 1.07809, saving model to /home/pavel/MyDocs/MachineLearning/Yandex_ML_project/lecture4/Kaggle_phonetics/baseline_model_weights.hdf5\n",
      "Epoch 15/100\n",
      "3394/3394 [==============================] - 7s 2ms/step - loss: 1.1031 - val_loss: 1.0652\n",
      "\n",
      "Epoch 00015: val_loss improved from 1.07809 to 1.06521, saving model to /home/pavel/MyDocs/MachineLearning/Yandex_ML_project/lecture4/Kaggle_phonetics/baseline_model_weights.hdf5\n",
      "Epoch 16/100\n",
      "3394/3394 [==============================] - 8s 2ms/step - loss: 1.0642 - val_loss: 1.0420\n",
      "\n",
      "Epoch 00016: val_loss improved from 1.06521 to 1.04196, saving model to /home/pavel/MyDocs/MachineLearning/Yandex_ML_project/lecture4/Kaggle_phonetics/baseline_model_weights.hdf5\n",
      "Epoch 17/100\n",
      "3394/3394 [==============================] - 6s 2ms/step - loss: 1.0377 - val_loss: 1.0181\n",
      "\n",
      "Epoch 00017: val_loss improved from 1.04196 to 1.01808, saving model to /home/pavel/MyDocs/MachineLearning/Yandex_ML_project/lecture4/Kaggle_phonetics/baseline_model_weights.hdf5\n",
      "Epoch 18/100\n",
      "3394/3394 [==============================] - 6s 2ms/step - loss: 1.0140 - val_loss: 1.0025\n",
      "\n",
      "Epoch 00018: val_loss improved from 1.01808 to 1.00251, saving model to /home/pavel/MyDocs/MachineLearning/Yandex_ML_project/lecture4/Kaggle_phonetics/baseline_model_weights.hdf5\n",
      "Epoch 19/100\n",
      "3394/3394 [==============================] - 7s 2ms/step - loss: 1.0114 - val_loss: 0.9857\n",
      "\n",
      "Epoch 00019: val_loss improved from 1.00251 to 0.98570, saving model to /home/pavel/MyDocs/MachineLearning/Yandex_ML_project/lecture4/Kaggle_phonetics/baseline_model_weights.hdf5\n",
      "Epoch 20/100\n",
      "3394/3394 [==============================] - 8s 2ms/step - loss: 0.9758 - val_loss: 0.9618\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.98570 to 0.96175, saving model to /home/pavel/MyDocs/MachineLearning/Yandex_ML_project/lecture4/Kaggle_phonetics/baseline_model_weights.hdf5\n",
      "Epoch 21/100\n",
      "3394/3394 [==============================] - 9s 3ms/step - loss: 0.9522 - val_loss: 0.9403\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.96175 to 0.94027, saving model to /home/pavel/MyDocs/MachineLearning/Yandex_ML_project/lecture4/Kaggle_phonetics/baseline_model_weights.hdf5\n",
      "Epoch 22/100\n",
      "3394/3394 [==============================] - 6s 2ms/step - loss: 0.9396 - val_loss: 0.9336\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.94027 to 0.93358, saving model to /home/pavel/MyDocs/MachineLearning/Yandex_ML_project/lecture4/Kaggle_phonetics/baseline_model_weights.hdf5\n",
      "Epoch 23/100\n",
      "3394/3394 [==============================] - 6s 2ms/step - loss: 0.9241 - val_loss: 0.9309\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.93358 to 0.93089, saving model to /home/pavel/MyDocs/MachineLearning/Yandex_ML_project/lecture4/Kaggle_phonetics/baseline_model_weights.hdf5\n",
      "Epoch 24/100\n",
      "3394/3394 [==============================] - 6s 2ms/step - loss: 0.9048 - val_loss: 0.9041\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.93089 to 0.90408, saving model to /home/pavel/MyDocs/MachineLearning/Yandex_ML_project/lecture4/Kaggle_phonetics/baseline_model_weights.hdf5\n",
      "Epoch 25/100\n",
      "3394/3394 [==============================] - 7s 2ms/step - loss: 0.8775 - val_loss: 0.8692\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.90408 to 0.86919, saving model to /home/pavel/MyDocs/MachineLearning/Yandex_ML_project/lecture4/Kaggle_phonetics/baseline_model_weights.hdf5\n",
      "Epoch 26/100\n",
      "3394/3394 [==============================] - 10s 3ms/step - loss: 0.8548 - val_loss: 0.8558\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.86919 to 0.85578, saving model to /home/pavel/MyDocs/MachineLearning/Yandex_ML_project/lecture4/Kaggle_phonetics/baseline_model_weights.hdf5\n",
      "Epoch 27/100\n",
      "3394/3394 [==============================] - 7s 2ms/step - loss: 0.8276 - val_loss: 0.8273\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.85578 to 0.82728, saving model to /home/pavel/MyDocs/MachineLearning/Yandex_ML_project/lecture4/Kaggle_phonetics/baseline_model_weights.hdf5\n",
      "Epoch 28/100\n",
      "3394/3394 [==============================] - 6s 2ms/step - loss: 0.8023 - val_loss: 0.8145\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.82728 to 0.81454, saving model to /home/pavel/MyDocs/MachineLearning/Yandex_ML_project/lecture4/Kaggle_phonetics/baseline_model_weights.hdf5\n",
      "Epoch 29/100\n",
      "3394/3394 [==============================] - 6s 2ms/step - loss: 0.7798 - val_loss: 0.7987\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.81454 to 0.79871, saving model to /home/pavel/MyDocs/MachineLearning/Yandex_ML_project/lecture4/Kaggle_phonetics/baseline_model_weights.hdf5\n",
      "Epoch 30/100\n",
      "3394/3394 [==============================] - 6s 2ms/step - loss: 0.7571 - val_loss: 0.7721\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.79871 to 0.77213, saving model to /home/pavel/MyDocs/MachineLearning/Yandex_ML_project/lecture4/Kaggle_phonetics/baseline_model_weights.hdf5\n",
      "Epoch 31/100\n",
      "3394/3394 [==============================] - 6s 2ms/step - loss: 0.7300 - val_loss: 0.7467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00031: val_loss improved from 0.77213 to 0.74667, saving model to /home/pavel/MyDocs/MachineLearning/Yandex_ML_project/lecture4/Kaggle_phonetics/baseline_model_weights.hdf5\n",
      "Epoch 32/100\n",
      "3394/3394 [==============================] - 7s 2ms/step - loss: 0.7028 - val_loss: 0.7405\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.74667 to 0.74046, saving model to /home/pavel/MyDocs/MachineLearning/Yandex_ML_project/lecture4/Kaggle_phonetics/baseline_model_weights.hdf5\n",
      "Epoch 33/100\n",
      "3394/3394 [==============================] - 6s 2ms/step - loss: 0.6884 - val_loss: 0.7089\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.74046 to 0.70885, saving model to /home/pavel/MyDocs/MachineLearning/Yandex_ML_project/lecture4/Kaggle_phonetics/baseline_model_weights.hdf5\n",
      "Epoch 34/100\n",
      "3394/3394 [==============================] - 6s 2ms/step - loss: 0.6643 - val_loss: 0.6962\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.70885 to 0.69620, saving model to /home/pavel/MyDocs/MachineLearning/Yandex_ML_project/lecture4/Kaggle_phonetics/baseline_model_weights.hdf5\n",
      "Epoch 35/100\n",
      "3394/3394 [==============================] - 6s 2ms/step - loss: 0.6563 - val_loss: 0.6794\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.69620 to 0.67943, saving model to /home/pavel/MyDocs/MachineLearning/Yandex_ML_project/lecture4/Kaggle_phonetics/baseline_model_weights.hdf5\n",
      "Epoch 36/100\n",
      "3394/3394 [==============================] - 6s 2ms/step - loss: 0.6266 - val_loss: 0.6591\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.67943 to 0.65911, saving model to /home/pavel/MyDocs/MachineLearning/Yandex_ML_project/lecture4/Kaggle_phonetics/baseline_model_weights.hdf5\n",
      "Epoch 37/100\n",
      "3394/3394 [==============================] - 6s 2ms/step - loss: 0.6079 - val_loss: 0.6452\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.65911 to 0.64524, saving model to /home/pavel/MyDocs/MachineLearning/Yandex_ML_project/lecture4/Kaggle_phonetics/baseline_model_weights.hdf5\n",
      "Epoch 38/100\n",
      "3394/3394 [==============================] - 6s 2ms/step - loss: 0.5939 - val_loss: 0.6365\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.64524 to 0.63645, saving model to /home/pavel/MyDocs/MachineLearning/Yandex_ML_project/lecture4/Kaggle_phonetics/baseline_model_weights.hdf5\n",
      "Epoch 39/100\n",
      "3394/3394 [==============================] - 6s 2ms/step - loss: 0.5740 - val_loss: 0.6303\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.63645 to 0.63034, saving model to /home/pavel/MyDocs/MachineLearning/Yandex_ML_project/lecture4/Kaggle_phonetics/baseline_model_weights.hdf5\n",
      "Epoch 40/100\n",
      "3394/3394 [==============================] - 6s 2ms/step - loss: 0.5630 - val_loss: 0.6241\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.63034 to 0.62415, saving model to /home/pavel/MyDocs/MachineLearning/Yandex_ML_project/lecture4/Kaggle_phonetics/baseline_model_weights.hdf5\n",
      "Epoch 41/100\n",
      "3394/3394 [==============================] - 6s 2ms/step - loss: 0.5466 - val_loss: 0.6104\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.62415 to 0.61036, saving model to /home/pavel/MyDocs/MachineLearning/Yandex_ML_project/lecture4/Kaggle_phonetics/baseline_model_weights.hdf5\n",
      "Epoch 42/100\n",
      "3394/3394 [==============================] - 6s 2ms/step - loss: 0.5285 - val_loss: 0.6054\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.61036 to 0.60544, saving model to /home/pavel/MyDocs/MachineLearning/Yandex_ML_project/lecture4/Kaggle_phonetics/baseline_model_weights.hdf5\n",
      "Epoch 43/100\n",
      "3394/3394 [==============================] - 6s 2ms/step - loss: 0.5190 - val_loss: 0.5883\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.60544 to 0.58826, saving model to /home/pavel/MyDocs/MachineLearning/Yandex_ML_project/lecture4/Kaggle_phonetics/baseline_model_weights.hdf5\n",
      "Epoch 44/100\n",
      "3394/3394 [==============================] - 6s 2ms/step - loss: 0.5065 - val_loss: 0.5752\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.58826 to 0.57523, saving model to /home/pavel/MyDocs/MachineLearning/Yandex_ML_project/lecture4/Kaggle_phonetics/baseline_model_weights.hdf5\n",
      "Epoch 45/100\n",
      "3394/3394 [==============================] - 6s 2ms/step - loss: 0.4877 - val_loss: 0.5610\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.57523 to 0.56098, saving model to /home/pavel/MyDocs/MachineLearning/Yandex_ML_project/lecture4/Kaggle_phonetics/baseline_model_weights.hdf5\n",
      "Epoch 46/100\n",
      "3394/3394 [==============================] - 6s 2ms/step - loss: 0.4741 - val_loss: 0.5660\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.56098\n",
      "Epoch 47/100\n",
      "3394/3394 [==============================] - 6s 2ms/step - loss: 0.4605 - val_loss: 0.5534\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.56098 to 0.55343, saving model to /home/pavel/MyDocs/MachineLearning/Yandex_ML_project/lecture4/Kaggle_phonetics/baseline_model_weights.hdf5\n",
      "Epoch 48/100\n",
      "3394/3394 [==============================] - 6s 2ms/step - loss: 0.4522 - val_loss: 0.5423\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.55343 to 0.54225, saving model to /home/pavel/MyDocs/MachineLearning/Yandex_ML_project/lecture4/Kaggle_phonetics/baseline_model_weights.hdf5\n",
      "Epoch 49/100\n",
      "3394/3394 [==============================] - 6s 2ms/step - loss: 0.4349 - val_loss: 0.5385\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.54225 to 0.53853, saving model to /home/pavel/MyDocs/MachineLearning/Yandex_ML_project/lecture4/Kaggle_phonetics/baseline_model_weights.hdf5\n",
      "Epoch 50/100\n",
      "3394/3394 [==============================] - 6s 2ms/step - loss: 0.4250 - val_loss: 0.5292\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.53853 to 0.52921, saving model to /home/pavel/MyDocs/MachineLearning/Yandex_ML_project/lecture4/Kaggle_phonetics/baseline_model_weights.hdf5\n",
      "Epoch 51/100\n",
      "3394/3394 [==============================] - 8s 2ms/step - loss: 0.4188 - val_loss: 0.5491\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.52921\n",
      "Epoch 52/100\n",
      "3394/3394 [==============================] - 8s 2ms/step - loss: 0.4176 - val_loss: 0.5208\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.52921 to 0.52082, saving model to /home/pavel/MyDocs/MachineLearning/Yandex_ML_project/lecture4/Kaggle_phonetics/baseline_model_weights.hdf5\n",
      "Epoch 53/100\n",
      "3394/3394 [==============================] - 7s 2ms/step - loss: 0.3960 - val_loss: 0.5088\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.52082 to 0.50877, saving model to /home/pavel/MyDocs/MachineLearning/Yandex_ML_project/lecture4/Kaggle_phonetics/baseline_model_weights.hdf5\n",
      "Epoch 54/100\n",
      "3394/3394 [==============================] - 7s 2ms/step - loss: 0.3812 - val_loss: 0.5070\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.50877 to 0.50697, saving model to /home/pavel/MyDocs/MachineLearning/Yandex_ML_project/lecture4/Kaggle_phonetics/baseline_model_weights.hdf5\n",
      "Epoch 55/100\n",
      "3394/3394 [==============================] - 8s 2ms/step - loss: 0.3740 - val_loss: 0.5150\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.50697\n",
      "Epoch 56/100\n",
      "3394/3394 [==============================] - 7s 2ms/step - loss: 0.3655 - val_loss: 0.5037\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.50697 to 0.50368, saving model to /home/pavel/MyDocs/MachineLearning/Yandex_ML_project/lecture4/Kaggle_phonetics/baseline_model_weights.hdf5\n",
      "Epoch 57/100\n",
      "3394/3394 [==============================] - 7s 2ms/step - loss: 0.3533 - val_loss: 0.5062\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.50368\n",
      "Epoch 58/100\n",
      "3394/3394 [==============================] - 6s 2ms/step - loss: 0.3482 - val_loss: 0.4959\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.50368 to 0.49594, saving model to /home/pavel/MyDocs/MachineLearning/Yandex_ML_project/lecture4/Kaggle_phonetics/baseline_model_weights.hdf5\n",
      "Epoch 59/100\n",
      "3394/3394 [==============================] - 6s 2ms/step - loss: 0.3393 - val_loss: 0.4903\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.49594 to 0.49026, saving model to /home/pavel/MyDocs/MachineLearning/Yandex_ML_project/lecture4/Kaggle_phonetics/baseline_model_weights.hdf5\n",
      "Epoch 60/100\n",
      "3394/3394 [==============================] - 6s 2ms/step - loss: 0.3273 - val_loss: 0.4881\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.49026 to 0.48805, saving model to /home/pavel/MyDocs/MachineLearning/Yandex_ML_project/lecture4/Kaggle_phonetics/baseline_model_weights.hdf5\n",
      "Epoch 61/100\n",
      "3394/3394 [==============================] - 6s 2ms/step - loss: 0.3180 - val_loss: 0.4817\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.48805 to 0.48174, saving model to /home/pavel/MyDocs/MachineLearning/Yandex_ML_project/lecture4/Kaggle_phonetics/baseline_model_weights.hdf5\n",
      "Epoch 62/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3394/3394 [==============================] - 6s 2ms/step - loss: 0.3157 - val_loss: 0.4925\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.48174\n",
      "Epoch 63/100\n",
      "3394/3394 [==============================] - 6s 2ms/step - loss: 0.3063 - val_loss: 0.4888\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.48174\n",
      "Epoch 64/100\n",
      "3394/3394 [==============================] - 6s 2ms/step - loss: 0.2959 - val_loss: 0.4799\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.48174 to 0.47993, saving model to /home/pavel/MyDocs/MachineLearning/Yandex_ML_project/lecture4/Kaggle_phonetics/baseline_model_weights.hdf5\n",
      "Epoch 65/100\n",
      "3394/3394 [==============================] - 6s 2ms/step - loss: 0.2861 - val_loss: 0.4867\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.47993\n",
      "Epoch 66/100\n",
      "3394/3394 [==============================] - 6s 2ms/step - loss: 0.2786 - val_loss: 0.4831\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.47993\n",
      "Epoch 67/100\n",
      "3394/3394 [==============================] - 7s 2ms/step - loss: 0.2719 - val_loss: 0.4755\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.47993 to 0.47547, saving model to /home/pavel/MyDocs/MachineLearning/Yandex_ML_project/lecture4/Kaggle_phonetics/baseline_model_weights.hdf5\n",
      "Epoch 68/100\n",
      "3394/3394 [==============================] - 6s 2ms/step - loss: 0.2637 - val_loss: 0.4840\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.47547\n",
      "Epoch 69/100\n",
      "3394/3394 [==============================] - 6s 2ms/step - loss: 0.2537 - val_loss: 0.4749\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.47547 to 0.47492, saving model to /home/pavel/MyDocs/MachineLearning/Yandex_ML_project/lecture4/Kaggle_phonetics/baseline_model_weights.hdf5\n",
      "Epoch 70/100\n",
      "3394/3394 [==============================] - 6s 2ms/step - loss: 0.2441 - val_loss: 0.4837\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.47492\n",
      "Epoch 71/100\n",
      "3394/3394 [==============================] - 6s 2ms/step - loss: 0.2445 - val_loss: 0.4889\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.47492\n",
      "Epoch 72/100\n",
      "3394/3394 [==============================] - 6s 2ms/step - loss: 0.2395 - val_loss: 0.4795\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.47492\n"
     ]
    }
   ],
   "source": [
    "BASELINE_MODEL_WEIGHTS = \"/home/pavel/MyDocs/MachineLearning/Yandex_ML_project/lecture4/Kaggle_phonetics/baseline_model_weights.hdf5\"\n",
    "training_model, testing_encoder_model, testing_decoder_model = baseline_model()\n",
    "\n",
    "train(training_model, BASELINE_MODEL_WEIGHTS, char_input_train, phone_input_train, phone_output_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_baseline(input_char_seq, encoder, decoder):\n",
    "    state_vectors = encoder.predict(input_char_seq) \n",
    "    \n",
    "    prev_phone = np.zeros((1, 1, PHONE_TOKEN_COUNT))\n",
    "    prev_phone[0, 0, phone_to_id[START_PHONE_SYM]] = 1.\n",
    "    \n",
    "    end_found = False \n",
    "    pronunciation = '' \n",
    "    while not end_found:\n",
    "        decoder_output, h, c = decoder.predict([prev_phone] + state_vectors)\n",
    "        \n",
    "        # Predict the phoneme with the highest probability\n",
    "        predicted_phone_idx = np.argmax(decoder_output[0, -1, :])\n",
    "        predicted_phone = id_to_phone[predicted_phone_idx]\n",
    "        \n",
    "        pronunciation += predicted_phone + ' '\n",
    "        \n",
    "        if predicted_phone == END_PHONE_SYM or len(pronunciation.split()) > MAX_PHONE_SEQ_LEN: \n",
    "            end_found = True\n",
    "        \n",
    "        # Setup inputs for next time step\n",
    "        prev_phone = np.zeros((1, 1, PHONE_TOKEN_COUNT))\n",
    "        prev_phone[0, 0, predicted_phone_idx] = 1.\n",
    "        state_vectors = [h, c]\n",
    "        \n",
    "    return pronunciation.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper method for converting vector representations back into words\n",
    "def one_hot_matrix_to_word(char_seq):\n",
    "    word = ''\n",
    "    for char_vec in char_seq[0]:\n",
    "        if np.count_nonzero(char_vec) == 0:\n",
    "            break\n",
    "        hot_bit_idx = np.argmax(char_vec)\n",
    "        char = id_to_char[hot_bit_idx]\n",
    "        word += char\n",
    "    return word\n",
    "\n",
    "\n",
    "# Some words have multiple correct pronunciations\n",
    "# If a prediction matches any correct pronunciation, consider it correct.\n",
    "def is_correct(word,test_pronunciation):\n",
    "    correct_pronuns = phonetic_dict[word]\n",
    "    for correct_pronun in correct_pronuns:\n",
    "        if test_pronunciation == correct_pronun:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def sample_baseline_predictions(sample_count, word_decoder):\n",
    "    sample_indices = random.sample(range(TEST_EXAMPLE_COUNT), sample_count)\n",
    "    for example_idx in sample_indices:\n",
    "        example_char_seq = char_input_test[example_idx:example_idx+1]\n",
    "        predicted_pronun = predict_baseline(example_char_seq, testing_encoder_model, testing_decoder_model)\n",
    "        example_word = word_decoder(example_char_seq)\n",
    "        pred_is_correct = is_correct(example_word, predicted_pronun)\n",
    "        print('✅ ' if pred_is_correct else '❌ ', example_word,'-->', predicted_pronun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌  MAXTOR --> K AA1 M P T R AH0 S\n",
      "❌  BURBLED --> B ER1 L D\n",
      "❌  ABOUT --> OW1 B AH0 T\n",
      "❌  HARIS --> HH EH1 R S\n",
      "❌  BARNETT --> B AA1 R T AH0 N\n",
      "❌  WERNET --> W ER1 N AH0 T\n",
      "❌  YELLEN --> IY1 L IH0 N\n",
      "❌  TRANSGRESSIONS --> T R AE0 S N AA1 JH EH1 R Z\n",
      "✅  CHEZ --> CH EH1 Z\n",
      "❌  CUONG --> K OW1 N IH0 NG\n"
     ]
    }
   ],
   "source": [
    "training_model.load_weights(BASELINE_MODEL_WEIGHTS)  # also loads weights for testing models\n",
    "sample_baseline_predictions(10, one_hot_matrix_to_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FURR'S -- 1 syllables\n",
      "CONTRASTS -- 2 syllables\n",
      "MEIDINGER -- 3 syllables\n"
     ]
    }
   ],
   "source": [
    "def syllable_count(phonetic_sp): \n",
    "    count = 0\n",
    "    for phone in phonetic_sp.split(): \n",
    "        if phone[-1].isdigit():\n",
    "            count += 1 \n",
    "    return count\n",
    "\n",
    "# Examples:\n",
    "for ex_word in list(phonetic_dict.keys())[:3]:\n",
    "    print(ex_word, '--', syllable_count(phonetic_dict[ex_word][0]), 'syllables')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "\n",
    "def is_syllable_count_correct(word, test_pronunciation):\n",
    "    correct_pronuns = phonetic_dict[word]\n",
    "    for correct_pronun in correct_pronuns:\n",
    "        if syllable_count(test_pronunciation) == syllable_count(correct_pronun):\n",
    "            return True\n",
    "    return False\n",
    "    \n",
    "    \n",
    "def bleu_score(word,test_pronunciation):\n",
    "    references = [pronun.split() for pronun in phonetic_dict[word]]\n",
    "    smooth = SmoothingFunction().method1\n",
    "    return sentence_bleu(references, test_pronunciation.split(), smoothing_function=smooth)\n",
    "\n",
    "\n",
    "def evaluate(test_examples, encoder, decoder, word_decoder, predictor):\n",
    "    correct_syllable_counts = 0\n",
    "    perfect_predictions = 0\n",
    "    bleu_scores = []\n",
    "    \n",
    "    for example_idx in range(TEST_EXAMPLE_COUNT):\n",
    "        example_char_seq = test_examples[example_idx:example_idx+1]\n",
    "        predicted_pronun = predictor(example_char_seq, encoder, decoder)\n",
    "        example_word = word_decoder(example_char_seq)\n",
    "        \n",
    "        perfect_predictions += is_correct(example_word,predicted_pronun)\n",
    "        correct_syllable_counts += is_syllable_count_correct(example_word,predicted_pronun)\n",
    "\n",
    "        bleu = bleu_score(example_word,predicted_pronun)\n",
    "        bleu_scores.append(bleu)\n",
    "        \n",
    "    syllable_acc = correct_syllable_counts / TEST_EXAMPLE_COUNT\n",
    "    perfect_acc = perfect_predictions / TEST_EXAMPLE_COUNT\n",
    "    avg_bleu_score = np.mean(bleu_scores)\n",
    "    \n",
    "    return syllable_acc, perfect_acc, avg_bleu_score\n",
    "\n",
    "\n",
    "def print_results(model_name, syllable_acc, perfect_acc, avg_bleu_score):\n",
    "    print(model_name)\n",
    "    print('-'*20)\n",
    "    print('Syllable Accuracy: %s%%' % round(syllable_acc*100, 1))\n",
    "    print('Perfect Accuracy: %s%%' % round(perfect_acc*100, 1))\n",
    "    print('Bleu Score: %s' % round(avg_bleu_score, 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Model\n",
      "--------------------\n",
      "Syllable Accuracy: 67.3%\n",
      "Perfect Accuracy: 11.0%\n",
      "Bleu Score: 0.2567\n"
     ]
    }
   ],
   "source": [
    "syllable_acc, perfect_acc, avg_bleu_score = evaluate(\n",
    "    char_input_test, testing_encoder_model, testing_decoder_model, one_hot_matrix_to_word, predict_baseline)\n",
    "print_results('Baseline Model',syllable_acc, perfect_acc, avg_bleu_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
