{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples in test dataset: 83194\n"
     ]
    }
   ],
   "source": [
    "train_file = open(\"/home/pavel/MyDocs/MachineLearning/Yandex_ML_project/lecture4/Kaggle_phonetics/train.txt\",\"r\")\n",
    "train = train_file.read()\n",
    "train = train.split('\\n')\n",
    "train = train[:-1]\n",
    "print(\"Examples in test dataset:\", len(train))\n",
    "x_train = [data_example.split(' ')[0] for data_example in train]\n",
    "y_train = [data_example.split(' ')[1] for data_example in train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_copy = x_train.copy()\n",
    "y_train_copy = y_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train_copy[:83000]\n",
    "y_train = y_train_copy[:83000]\n",
    "x_test = x_train_copy[83000:]\n",
    "y_test = y_train_copy[83000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LEMIEUX'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_phonetic_dict(x, y):\n",
    "    phonetic_dict = {}\n",
    "    for i in range(len(x)):\n",
    "        if x[i] not in phonetic_dict:\n",
    "            phonetic_dict[x[i]] = []\n",
    "        phonetic_dict[x[i]].append(y[i])\n",
    "    return phonetic_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "phonetic_dict = get_phonetic_dict(x_train, y_train)\n",
    "example_count = np.sum([len(prons) for _, prons in phonetic_dict.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KOEHN --> K_OW_N\n",
      "BEAVIS --> B_IY_V_AH_S\n",
      "MOTHERSHEAD --> M_AH_DH_ER_Z_HH_EH_D\n",
      "HEATEDLY --> HH_IY_T_IH_D_L_IY\n",
      "VICTORIOUS --> V_IH_K_T_AO_R_IY_AH_S\n",
      "BENJAMIN'S --> B_EH_N_JH_AH_M_AH_N_Z\n",
      "CABE --> K_EY_B\n",
      "SILVIUS --> S_IH_L_V_IY_IH_S\n",
      "WRINKLING --> R_IH_NG_K_AH_L_IH_NG\n",
      "JEANCOURT --> JH_IY_N_K_AO_R_T\n",
      "\n",
      "After cleaning, the dictionary contains 83000 words and 83000 pronunciations (0 are alternate pronunciations).\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join([k+' --> '+phonetic_dict[k][0] for k in random.sample(list(phonetic_dict.keys()), 10)]))\n",
    "print('\\nAfter cleaning, the dictionary contains %s words and %s pronunciations (%s are alternate pronunciations).' % \n",
    "      (len(phonetic_dict), example_count, (example_count-len(phonetic_dict))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Char to id mapping: \n",
      " {'': 0, 'L': 1, 'E': 2, 'M': 3, 'I': 4, 'U': 5, 'X': 6, 'N': 7, 'D': 8, 'G': 9, 'S': 10, 'T': 11, 'R': 12, 'P': 13, 'K': 14, 'C': 15, 'O': 16, 'F': 17, 'A': 18, 'B': 19, 'H': 20, 'V': 21, 'Y': 22, 'W': 23, 'J': 24, \"'\": 25, 'Q': 26, 'Z': 27, '-': 28}\n",
      "Phone to id mapping: \n",
      " {'': 0, 's': 1, 'e': 2, 'L': 3, 'AH': 4, 'M': 5, 'Y': 6, 'UW': 7, 'AY': 8, 'N': 9, 'D': 10, 'IH': 11, 'NG': 12, 'S': 13, 'T': 14, 'R': 15, 'P': 16, 'K': 17, 'EH': 18, 'AA': 19, 'F': 20, 'ER': 21, 'EY': 22, 'AE': 23, 'Z': 24, 'G': 25, 'B': 26, 'SH': 27, 'V': 28, 'OW': 29, 'AO': 30, 'IY': 31, 'W': 32, 'HH': 33, 'JH': 34, 'CH': 35, 'TH': 36, 'AW': 37, 'OY': 38, 'UH': 39, 'ZH': 40, 'DH': 41}\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "START_PHONE_SYM = 's'\n",
    "END_PHONE_SYM = 'e'\n",
    "\n",
    "\n",
    "def char_list():\n",
    "    allowed_symbols = ['']\n",
    "    for word in x_train:\n",
    "        for char in word:\n",
    "            if char not in allowed_symbols:\n",
    "                allowed_symbols.append(char)\n",
    "    return allowed_symbols\n",
    "\n",
    "\n",
    "def phone_list():\n",
    "    phone_list = [START_PHONE_SYM, END_PHONE_SYM]\n",
    "    for transcription in y_train:\n",
    "        for phone in transcription.split('_'):\n",
    "            if phone not in phone_list:\n",
    "                phone_list.append(phone)\n",
    "    return [''] + phone_list\n",
    "\n",
    "\n",
    "def id_mappings_from_list(str_list):\n",
    "    str_to_id = {s: i for i, s in enumerate(str_list)} \n",
    "    id_to_str = {i: s for i, s in enumerate(str_list)}\n",
    "    return str_to_id, id_to_str\n",
    "\n",
    "\n",
    "# Create character to ID mappings\n",
    "char_to_id, id_to_char = id_mappings_from_list(char_list())\n",
    "\n",
    "# Load phonetic symbols and create ID mappings\n",
    "phone_to_id, id_to_phone = id_mappings_from_list(phone_list())\n",
    "\n",
    "# Example:\n",
    "print('Char to id mapping: \\n', char_to_id)\n",
    "print('Phone to id mapping: \\n', phone_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A\" is represented by:\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.] \n",
      "-----\n",
      "\"AH\" is represented by:\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "CHAR_TOKEN_COUNT = len(char_to_id)\n",
    "PHONE_TOKEN_COUNT = len(phone_to_id)\n",
    "\n",
    "\n",
    "def char_to_1_hot(char):\n",
    "    char_id = char_to_id[char]\n",
    "    hot_vec = np.zeros((CHAR_TOKEN_COUNT))\n",
    "    hot_vec[char_id] = 1.\n",
    "    return hot_vec\n",
    "\n",
    "\n",
    "def phone_to_1_hot(phone):\n",
    "    phone_id = phone_to_id[phone]\n",
    "    hot_vec = np.zeros((PHONE_TOKEN_COUNT))\n",
    "    hot_vec[phone_id] = 1.\n",
    "    return hot_vec\n",
    "\n",
    "# Example:\n",
    "print('\"A\" is represented by:\\n', char_to_1_hot('A'), '\\n-----')\n",
    "print('\"AH\" is represented by:\\n', phone_to_1_hot('AH'))\n",
    "MAX_CHAR_SEQ_LEN = max([len(word) for word, _ in phonetic_dict.items()])\n",
    "MAX_PHONE_SEQ_LEN = max([max([len(pron.split('_')) for pron in pronuns]) \n",
    "                         for _, pronuns in phonetic_dict.items()]\n",
    "                       ) + 2  # + 2 to account for the start & end tokens we need to add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Matrix Shape:  (83000, 34, 29)\n",
      "Pronunciation Matrix Shape:  (83000, 34, 42)\n"
     ]
    }
   ],
   "source": [
    "def dataset_to_1_hot_tensors():\n",
    "    char_seqs = []\n",
    "    phone_seqs = []\n",
    "    \n",
    "    for word, pronuns in phonetic_dict.items():\n",
    "        word_matrix = np.zeros((MAX_CHAR_SEQ_LEN, CHAR_TOKEN_COUNT))\n",
    "        for t, char in enumerate(word):\n",
    "            word_matrix[t, :] = char_to_1_hot(char)\n",
    "        for pronun in pronuns:\n",
    "            pronun_matrix = np.zeros((MAX_PHONE_SEQ_LEN, PHONE_TOKEN_COUNT))\n",
    "            phones = [START_PHONE_SYM] + pronun.split('_') + [END_PHONE_SYM]\n",
    "            for t, phone in enumerate(phones):\n",
    "                pronun_matrix[t,:] = phone_to_1_hot(phone)\n",
    "                \n",
    "            char_seqs.append(word_matrix)\n",
    "            phone_seqs.append(pronun_matrix)\n",
    "    \n",
    "    return np.array(char_seqs), np.array(phone_seqs)\n",
    "            \n",
    "\n",
    "char_seq_matrix, phone_seq_matrix = dataset_to_1_hot_tensors()        \n",
    "print('Word Matrix Shape: ', char_seq_matrix.shape)\n",
    "print('Pronunciation Matrix Shape: ', phone_seq_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding Word Matrix Shape:  (83000, 34)\n",
      "Embedding Phoneme Matrix Shape:  (83000, 34)\n"
     ]
    }
   ],
   "source": [
    "def dataset_for_embeddings():\n",
    "    char_seqs = []\n",
    "    phone_seqs = []\n",
    "    \n",
    "    for word,pronuns in phonetic_dict.items():\n",
    "        word_matrix = np.zeros((MAX_CHAR_SEQ_LEN))\n",
    "        for t,char in enumerate(word):\n",
    "            word_matrix[t] = char_to_id[char]\n",
    "        for pronun in pronuns:\n",
    "            pronun_matrix = np.zeros((MAX_PHONE_SEQ_LEN))\n",
    "            phones = [START_PHONE_SYM] + pronun.split('_') + [END_PHONE_SYM]\n",
    "            for t, phone in enumerate(phones):\n",
    "                pronun_matrix[t] = phone_to_id[phone]\n",
    "                \n",
    "            char_seqs.append(word_matrix)\n",
    "            phone_seqs.append(pronun_matrix)\n",
    "    \n",
    "    return np.array(char_seqs), np.array(phone_seqs)\n",
    "\n",
    "            \n",
    "char_emb_matrix, phone_emb_matrix = dataset_for_embeddings()        \n",
    "\n",
    "print('Embedding Word Matrix Shape: ', char_emb_matrix.shape)\n",
    "print('Embedding Phoneme Matrix Shape: ', phone_emb_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "phone_seq_matrix_decoder_output = np.pad(phone_seq_matrix,((0,0),(0,1),(0,0)), mode='constant')[:,1:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "TEST_SIZE = 0\n",
    "\n",
    "(char_input_train, char_input_test, \n",
    " phone_input_train, phone_input_test, \n",
    " phone_output_train, phone_output_test) = train_test_split(\n",
    "    char_seq_matrix, phone_seq_matrix, phone_seq_matrix_decoder_output, \n",
    "    test_size=TEST_SIZE, random_state=42)\n",
    "\n",
    "(emb_char_input_train, emb_char_input_test, \n",
    " emb_phone_input_train, emb_phone_input_test) = train_test_split(\n",
    "    char_emb_matrix, phone_emb_matrix, test_size=TEST_SIZE, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.activations import softmax\n",
    "from keras.layers import Input, LSTM, Dense, Dropout, Embedding,Activation, Bidirectional, Concatenate, Permute, Dot, Multiply, Reshape, RepeatVector, Lambda, Flatten\n",
    "def attention_model(hidden_nodes = 256, emb_size = 256):\n",
    "    # Attention Mechanism Layers\n",
    "    attn_repeat = RepeatVector(MAX_CHAR_SEQ_LEN)\n",
    "    attn_concat = Concatenate(axis=-1)\n",
    "    attn_dense1 = Dense(128, activation=\"tanh\")\n",
    "    attn_dense2 = Dense(1, activation=\"relu\")\n",
    "    attn_softmax = Lambda(lambda x: softmax(x,axis=1))\n",
    "    attn_dot = Dot(axes = 1)\n",
    "    \n",
    "    def get_context(encoder_outputs, h_prev):\n",
    "        h_prev = attn_repeat(h_prev)\n",
    "        concat = attn_concat([encoder_outputs, h_prev])\n",
    "        e = attn_dense1(concat)\n",
    "        e = attn_dense2(e)\n",
    "        attention_weights = attn_softmax(e)\n",
    "        context = attn_dot([attention_weights, encoder_outputs])\n",
    "        return context\n",
    "    \n",
    "    # Shared Components - Encoder\n",
    "    char_inputs = Input(shape=(None,))\n",
    "    char_embedding_layer = Embedding(CHAR_TOKEN_COUNT, emb_size, input_length=MAX_CHAR_SEQ_LEN)\n",
    "    encoder = Bidirectional(LSTM(hidden_nodes, return_sequences=True, recurrent_dropout=0.2))\n",
    "    \n",
    "    # Shared Components - Decoder\n",
    "    decoder = LSTM(hidden_nodes, return_state=True, recurrent_dropout=0.2)\n",
    "    phone_embedding_layer = Embedding(PHONE_TOKEN_COUNT, emb_size)\n",
    "    embedding_reshaper = Reshape((1,emb_size,))\n",
    "    context_phone_concat = Concatenate(axis=-1)\n",
    "    context_phone_dense = Dense(hidden_nodes*3, activation=\"relu\")\n",
    "    output_layer = Dense(PHONE_TOKEN_COUNT, activation='softmax')\n",
    "    \n",
    "    # Training Model - Encoder\n",
    "    char_embeddings = char_embedding_layer(char_inputs)\n",
    "    char_embeddings = Activation('relu')(char_embeddings)\n",
    "    char_embeddings = Dropout(0.5)(char_embeddings)\n",
    "    encoder_outputs = encoder(char_embeddings)\n",
    "    \n",
    "    # Training Model - Attention Decoder\n",
    "    h0 = Input(shape=(hidden_nodes,))\n",
    "    c0 = Input(shape=(hidden_nodes,))\n",
    "    h = h0 # hidden state\n",
    "    c = c0 # cell state\n",
    "    \n",
    "    phone_inputs = []\n",
    "    phone_outputs = []\n",
    "    \n",
    "    for t in range(MAX_PHONE_SEQ_LEN):\n",
    "        phone_input = Input(shape=(None,))\n",
    "        phone_embeddings = phone_embedding_layer(phone_input)\n",
    "        phone_embeddings = Dropout(0.5)(phone_embeddings)\n",
    "        phone_embeddings = embedding_reshaper(phone_embeddings)\n",
    "        \n",
    "        context = get_context(encoder_outputs, h)\n",
    "        phone_and_context = context_phone_concat([context, phone_embeddings])\n",
    "        phone_and_context = context_phone_dense(phone_and_context)\n",
    "        \n",
    "        decoder_output, h, c = decoder(phone_and_context, initial_state = [h, c])\n",
    "        decoder_output = Dropout(0.5)(decoder_output)\n",
    "        phone_output = output_layer(decoder_output)\n",
    "        \n",
    "        phone_inputs.append(phone_input)\n",
    "        phone_outputs.append(phone_output)\n",
    "    \n",
    "    training_model = Model(inputs=[char_inputs, h0, c0] + phone_inputs, outputs=phone_outputs)\n",
    "    \n",
    "   # Testing Model - Encoder\n",
    "    testing_encoder_model = Model(char_inputs, encoder_outputs)\n",
    "\n",
    "    # Testing Model - Decoder\n",
    "    test_prev_phone_input = Input(shape=(None,))\n",
    "    test_phone_embeddings = phone_embedding_layer(test_prev_phone_input)\n",
    "    test_phone_embeddings = embedding_reshaper(test_phone_embeddings)\n",
    "    \n",
    "    test_h = Input(shape=(hidden_nodes,), name='test_h')\n",
    "    test_c = Input(shape=(hidden_nodes,), name='test_c')\n",
    "    \n",
    "    test_encoding_input = Input(shape=(MAX_CHAR_SEQ_LEN, hidden_nodes*2,))\n",
    "    test_context = get_context(test_encoding_input, test_h)\n",
    "    test_phone_and_context = Concatenate(axis=-1)([test_context, test_phone_embeddings])\n",
    "    test_phone_and_context = context_phone_dense(test_phone_and_context)\n",
    "        \n",
    "    test_seq, out_h, out_c = decoder(test_phone_and_context, initial_state = [test_h, test_c])\n",
    "    test_out = output_layer(test_seq)\n",
    "    \n",
    "    testing_decoder_model = Model([test_prev_phone_input, test_h, test_c, test_encoding_input], [test_out,out_h,out_c])\n",
    "    \n",
    "    return training_model, testing_encoder_model, testing_decoder_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "h0 = np.zeros((emb_char_input_train.shape[0], 256))\n",
    "c0 = np.zeros((emb_char_input_train.shape[0], 256))\n",
    "inputs = list(emb_phone_input_train.swapaxes(0,1))\n",
    "outputs = list(phone_output_train.swapaxes(0,1))\n",
    "\n",
    "def train_attention(model, weights_path, validation_size=0.1, epochs=5):    \n",
    "    \n",
    "    \n",
    "    callbacks = []\n",
    "    if validation_size > 0:\n",
    "        checkpointer = ModelCheckpoint(filepath=weights_path, verbose=1, save_best_only=True)\n",
    "        stopper = EarlyStopping(monitor='val_loss',patience=3)\n",
    "        callbacks = [checkpointer, stopper]\n",
    "\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "    model.fit([emb_char_input_train, h0, c0] + inputs, outputs,\n",
    "              batch_size=256,\n",
    "              epochs=epochs,\n",
    "              validation_split=validation_size,\n",
    "              callbacks=callbacks)\n",
    "    \n",
    "    if validation_size == 0:\n",
    "        model.save_weights(weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tran_loss  = 1.3416, val_loss = 1.2324, train_acc = 0.704, test_acc = 0.685, kaggle acc = 67.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train_loss = 1.3298   val_loss = 1.656   train_acc = 0.724  test_acc = 0.680    kaggle_acc = 67.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train_loss = 1.1843, val_loss = 1.1958, train_acc = 0.734, test_acc = 0.696, kaggle_acc = 68.579"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train_loss = 1.0159, val_loss = 1.13572, train_acc = 0.77, test_acc = 0.685, kaggle_acc = 0.70237"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 74700 samples, validate on 8300 samples\n",
      "Epoch 1/5\n",
      "74700/74700 [==============================] - 1549s 21ms/step - loss: 1.0162 - dense_8_loss: 0.0000e+00 - val_loss: 0.8529 - val_dense_8_loss: 0.0000e+00\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.85295, saving model to /home/pavel/MyDocs/MachineLearning/Yandex_ML_project/lecture4/Kaggle_phonetics/attention_model_weights.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pavel/anaconda3/envs/py36/lib/python3.6/site-packages/keras/engine/network.py:888: UserWarning: Layer lstm_4 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'input_41:0' shape=(?, 256) dtype=float32>, <tf.Tensor 'input_42:0' shape=(?, 256) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n",
      "/home/pavel/anaconda3/envs/py36/lib/python3.6/site-packages/keras/engine/network.py:888: UserWarning: Layer lstm_4 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_4/while/Exit_3:0' shape=(?, 256) dtype=float32>, <tf.Tensor 'lstm_4/while/Exit_4:0' shape=(?, 256) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n",
      "/home/pavel/anaconda3/envs/py36/lib/python3.6/site-packages/keras/engine/network.py:888: UserWarning: Layer lstm_4 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_4_1/while/Exit_3:0' shape=(?, 256) dtype=float32>, <tf.Tensor 'lstm_4_1/while/Exit_4:0' shape=(?, 256) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n",
      "/home/pavel/anaconda3/envs/py36/lib/python3.6/site-packages/keras/engine/network.py:888: UserWarning: Layer lstm_4 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_4_2/while/Exit_3:0' shape=(?, 256) dtype=float32>, <tf.Tensor 'lstm_4_2/while/Exit_4:0' shape=(?, 256) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n",
      "/home/pavel/anaconda3/envs/py36/lib/python3.6/site-packages/keras/engine/network.py:888: UserWarning: Layer lstm_4 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_4_3/while/Exit_3:0' shape=(?, 256) dtype=float32>, <tf.Tensor 'lstm_4_3/while/Exit_4:0' shape=(?, 256) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n",
      "/home/pavel/anaconda3/envs/py36/lib/python3.6/site-packages/keras/engine/network.py:888: UserWarning: Layer lstm_4 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_4_4/while/Exit_3:0' shape=(?, 256) dtype=float32>, <tf.Tensor 'lstm_4_4/while/Exit_4:0' shape=(?, 256) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n",
      "/home/pavel/anaconda3/envs/py36/lib/python3.6/site-packages/keras/engine/network.py:888: UserWarning: Layer lstm_4 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_4_5/while/Exit_3:0' shape=(?, 256) dtype=float32>, <tf.Tensor 'lstm_4_5/while/Exit_4:0' shape=(?, 256) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n",
      "/home/pavel/anaconda3/envs/py36/lib/python3.6/site-packages/keras/engine/network.py:888: UserWarning: Layer lstm_4 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_4_6/while/Exit_3:0' shape=(?, 256) dtype=float32>, <tf.Tensor 'lstm_4_6/while/Exit_4:0' shape=(?, 256) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n",
      "/home/pavel/anaconda3/envs/py36/lib/python3.6/site-packages/keras/engine/network.py:888: UserWarning: Layer lstm_4 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_4_7/while/Exit_3:0' shape=(?, 256) dtype=float32>, <tf.Tensor 'lstm_4_7/while/Exit_4:0' shape=(?, 256) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n",
      "/home/pavel/anaconda3/envs/py36/lib/python3.6/site-packages/keras/engine/network.py:888: UserWarning: Layer lstm_4 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_4_8/while/Exit_3:0' shape=(?, 256) dtype=float32>, <tf.Tensor 'lstm_4_8/while/Exit_4:0' shape=(?, 256) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n",
      "/home/pavel/anaconda3/envs/py36/lib/python3.6/site-packages/keras/engine/network.py:888: UserWarning: Layer lstm_4 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_4_9/while/Exit_3:0' shape=(?, 256) dtype=float32>, <tf.Tensor 'lstm_4_9/while/Exit_4:0' shape=(?, 256) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n",
      "/home/pavel/anaconda3/envs/py36/lib/python3.6/site-packages/keras/engine/network.py:888: UserWarning: Layer lstm_4 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_4_10/while/Exit_3:0' shape=(?, 256) dtype=float32>, <tf.Tensor 'lstm_4_10/while/Exit_4:0' shape=(?, 256) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n",
      "/home/pavel/anaconda3/envs/py36/lib/python3.6/site-packages/keras/engine/network.py:888: UserWarning: Layer lstm_4 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_4_11/while/Exit_3:0' shape=(?, 256) dtype=float32>, <tf.Tensor 'lstm_4_11/while/Exit_4:0' shape=(?, 256) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n",
      "/home/pavel/anaconda3/envs/py36/lib/python3.6/site-packages/keras/engine/network.py:888: UserWarning: Layer lstm_4 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_4_12/while/Exit_3:0' shape=(?, 256) dtype=float32>, <tf.Tensor 'lstm_4_12/while/Exit_4:0' shape=(?, 256) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n",
      "/home/pavel/anaconda3/envs/py36/lib/python3.6/site-packages/keras/engine/network.py:888: UserWarning: Layer lstm_4 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_4_13/while/Exit_3:0' shape=(?, 256) dtype=float32>, <tf.Tensor 'lstm_4_13/while/Exit_4:0' shape=(?, 256) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n",
      "/home/pavel/anaconda3/envs/py36/lib/python3.6/site-packages/keras/engine/network.py:888: UserWarning: Layer lstm_4 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_4_14/while/Exit_3:0' shape=(?, 256) dtype=float32>, <tf.Tensor 'lstm_4_14/while/Exit_4:0' shape=(?, 256) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n",
      "/home/pavel/anaconda3/envs/py36/lib/python3.6/site-packages/keras/engine/network.py:888: UserWarning: Layer lstm_4 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_4_15/while/Exit_3:0' shape=(?, 256) dtype=float32>, <tf.Tensor 'lstm_4_15/while/Exit_4:0' shape=(?, 256) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n",
      "/home/pavel/anaconda3/envs/py36/lib/python3.6/site-packages/keras/engine/network.py:888: UserWarning: Layer lstm_4 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_4_16/while/Exit_3:0' shape=(?, 256) dtype=float32>, <tf.Tensor 'lstm_4_16/while/Exit_4:0' shape=(?, 256) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n",
      "/home/pavel/anaconda3/envs/py36/lib/python3.6/site-packages/keras/engine/network.py:888: UserWarning: Layer lstm_4 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_4_17/while/Exit_3:0' shape=(?, 256) dtype=float32>, <tf.Tensor 'lstm_4_17/while/Exit_4:0' shape=(?, 256) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n",
      "/home/pavel/anaconda3/envs/py36/lib/python3.6/site-packages/keras/engine/network.py:888: UserWarning: Layer lstm_4 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_4_18/while/Exit_3:0' shape=(?, 256) dtype=float32>, <tf.Tensor 'lstm_4_18/while/Exit_4:0' shape=(?, 256) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n",
      "/home/pavel/anaconda3/envs/py36/lib/python3.6/site-packages/keras/engine/network.py:888: UserWarning: Layer lstm_4 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_4_19/while/Exit_3:0' shape=(?, 256) dtype=float32>, <tf.Tensor 'lstm_4_19/while/Exit_4:0' shape=(?, 256) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n",
      "/home/pavel/anaconda3/envs/py36/lib/python3.6/site-packages/keras/engine/network.py:888: UserWarning: Layer lstm_4 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_4_20/while/Exit_3:0' shape=(?, 256) dtype=float32>, <tf.Tensor 'lstm_4_20/while/Exit_4:0' shape=(?, 256) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n",
      "/home/pavel/anaconda3/envs/py36/lib/python3.6/site-packages/keras/engine/network.py:888: UserWarning: Layer lstm_4 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_4_21/while/Exit_3:0' shape=(?, 256) dtype=float32>, <tf.Tensor 'lstm_4_21/while/Exit_4:0' shape=(?, 256) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n",
      "/home/pavel/anaconda3/envs/py36/lib/python3.6/site-packages/keras/engine/network.py:888: UserWarning: Layer lstm_4 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_4_22/while/Exit_3:0' shape=(?, 256) dtype=float32>, <tf.Tensor 'lstm_4_22/while/Exit_4:0' shape=(?, 256) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n",
      "/home/pavel/anaconda3/envs/py36/lib/python3.6/site-packages/keras/engine/network.py:888: UserWarning: Layer lstm_4 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_4_23/while/Exit_3:0' shape=(?, 256) dtype=float32>, <tf.Tensor 'lstm_4_23/while/Exit_4:0' shape=(?, 256) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n",
      "/home/pavel/anaconda3/envs/py36/lib/python3.6/site-packages/keras/engine/network.py:888: UserWarning: Layer lstm_4 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_4_24/while/Exit_3:0' shape=(?, 256) dtype=float32>, <tf.Tensor 'lstm_4_24/while/Exit_4:0' shape=(?, 256) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n",
      "/home/pavel/anaconda3/envs/py36/lib/python3.6/site-packages/keras/engine/network.py:888: UserWarning: Layer lstm_4 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_4_25/while/Exit_3:0' shape=(?, 256) dtype=float32>, <tf.Tensor 'lstm_4_25/while/Exit_4:0' shape=(?, 256) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n",
      "/home/pavel/anaconda3/envs/py36/lib/python3.6/site-packages/keras/engine/network.py:888: UserWarning: Layer lstm_4 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_4_26/while/Exit_3:0' shape=(?, 256) dtype=float32>, <tf.Tensor 'lstm_4_26/while/Exit_4:0' shape=(?, 256) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n",
      "/home/pavel/anaconda3/envs/py36/lib/python3.6/site-packages/keras/engine/network.py:888: UserWarning: Layer lstm_4 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_4_27/while/Exit_3:0' shape=(?, 256) dtype=float32>, <tf.Tensor 'lstm_4_27/while/Exit_4:0' shape=(?, 256) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n",
      "/home/pavel/anaconda3/envs/py36/lib/python3.6/site-packages/keras/engine/network.py:888: UserWarning: Layer lstm_4 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_4_28/while/Exit_3:0' shape=(?, 256) dtype=float32>, <tf.Tensor 'lstm_4_28/while/Exit_4:0' shape=(?, 256) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n",
      "/home/pavel/anaconda3/envs/py36/lib/python3.6/site-packages/keras/engine/network.py:888: UserWarning: Layer lstm_4 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_4_29/while/Exit_3:0' shape=(?, 256) dtype=float32>, <tf.Tensor 'lstm_4_29/while/Exit_4:0' shape=(?, 256) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n",
      "/home/pavel/anaconda3/envs/py36/lib/python3.6/site-packages/keras/engine/network.py:888: UserWarning: Layer lstm_4 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_4_30/while/Exit_3:0' shape=(?, 256) dtype=float32>, <tf.Tensor 'lstm_4_30/while/Exit_4:0' shape=(?, 256) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n",
      "/home/pavel/anaconda3/envs/py36/lib/python3.6/site-packages/keras/engine/network.py:888: UserWarning: Layer lstm_4 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_4_31/while/Exit_3:0' shape=(?, 256) dtype=float32>, <tf.Tensor 'lstm_4_31/while/Exit_4:0' shape=(?, 256) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n",
      "/home/pavel/anaconda3/envs/py36/lib/python3.6/site-packages/keras/engine/network.py:888: UserWarning: Layer lstm_4 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_4_32/while/Exit_3:0' shape=(?, 256) dtype=float32>, <tf.Tensor 'lstm_4_32/while/Exit_4:0' shape=(?, 256) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5\n",
      "74700/74700 [==============================] - 1475s 20ms/step - loss: 1.0004 - dense_8_loss: 0.0000e+00 - val_loss: 0.8638 - val_dense_8_loss: 0.0000e+00\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.85295\n",
      "Epoch 3/5\n",
      "74700/74700 [==============================] - 1429s 19ms/step - loss: 0.9437 - dense_8_loss: 0.0000e+00 - val_loss: 0.8617 - val_dense_8_loss: 0.0000e+00\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.85295\n",
      "Epoch 4/5\n",
      "74700/74700 [==============================] - 1377s 18ms/step - loss: 0.9470 - dense_8_loss: 0.0000e+00 - val_loss: 0.9218 - val_dense_8_loss: 0.0000e+00\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.85295\n"
     ]
    }
   ],
   "source": [
    "ATTENTION_MODEL_WEIGHTS = \"/home/pavel/MyDocs/MachineLearning/Yandex_ML_project/lecture4/Kaggle_phonetics/attention_model_weights.hdf5\"\n",
    "attn_training_model, attn_testing_encoder_model, attn_testing_decoder_model = attention_model()\n",
    "attn_training_model.load_weights(ATTENTION_MODEL_WEIGHTS)\n",
    "\n",
    "train_attention(attn_training_model, ATTENTION_MODEL_WEIGHTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def id_vec_to_word(emb_char_seq):\n",
    "    word = ''\n",
    "    for char_id in emb_char_seq[0]:\n",
    "        char = id_to_char[char_id]\n",
    "        word += char\n",
    "    return word.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_attention(input_char_seq, encoder, decoder):\n",
    "    encoder_outputs = encoder.predict(input_char_seq) \n",
    "\n",
    "    output_phone_seq = np.array([[phone_to_id[START_PHONE_SYM]]])\n",
    "    \n",
    "    h = np.zeros((emb_char_input_train.shape[0], 256))\n",
    "    c = np.zeros((emb_char_input_train.shape[0], 256))\n",
    "    \n",
    "    end_found = False \n",
    "    pronunciation = '' \n",
    "    while not end_found:\n",
    "        decoder_output, h, c = decoder.predict([output_phone_seq, h, c, encoder_outputs])\n",
    "        \n",
    "        # Predict the phoneme with the highest probability\n",
    "        predicted_phone_idx = np.argmax(decoder_output[0,:])\n",
    "        predicted_phone = id_to_phone[predicted_phone_idx]\n",
    "        \n",
    "        pronunciation += predicted_phone + '_'\n",
    "        \n",
    "        if predicted_phone == END_PHONE_SYM or len(pronunciation.split('_')) > MAX_PHONE_SEQ_LEN: \n",
    "            end_found = True\n",
    "        \n",
    "        # Setup inputs for next time step\n",
    "        output_phone_seq = np.array([[predicted_phone_idx]])\n",
    "        \n",
    "    return pronunciation.strip('_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(x_data, y_data):\n",
    "    char_seqs = []\n",
    "    \n",
    "    for word in x_data:\n",
    "        word_matrix = np.zeros((MAX_CHAR_SEQ_LEN))\n",
    "        for t, char in enumerate(word):\n",
    "            word_matrix[t] = char_to_id[char]\n",
    "        char_seqs.append(word_matrix)\n",
    "\n",
    "    char_seq_matrix_test = np.array(char_seqs)\n",
    "    \n",
    "    y_predicted = []\n",
    "    for i in range(len(char_seq_matrix_test)):\n",
    "        example_char_seq = char_seq_matrix_test[i:i+1]\n",
    "        predicted_pronun = predict_attention(example_char_seq, attn_testing_encoder_model, attn_testing_decoder_model)\n",
    "        predicted_pronun = predicted_pronun[:-2] #strip _e symbol\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            print(i, '/', len(char_seq_matrix_test))\n",
    "            print(\"Word:\", x_data[i])\n",
    "            print(\"Transcription:\", y_data[i])\n",
    "            print(\"Prediction:\", predicted_pronun)\n",
    "            \n",
    "        y_predicted.append(predicted_pronun)\n",
    "    correct_num = 0\n",
    "    for i in range(len(x_data)):\n",
    "        if y_data[i] == y_predicted[i]:\n",
    "            correct_num += 1\n",
    "    \n",
    "    print(\"Prediction finished!!!\")\n",
    "    return correct_num/len(x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ATTENTION_MODEL_WEIGHTS = \"/home/pavel/MyDocs/MachineLearning/Yandex_ML_project/lecture4/Kaggle_phonetics/attention_model_weights_70237.hdf5\"\n",
    "attn_training_model, attn_testing_encoder_model, attn_testing_decoder_model = attention_model()\n",
    "attn_training_model.load_weights(ATTENTION_MODEL_WEIGHTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 500\n",
      "Word: LEMIEUX\n",
      "Transcription: L_AH_M_Y_UW\n",
      "Prediction: L_IY_M_IY_OW\n",
      "100 / 500\n",
      "Word: DISSENT\n",
      "Transcription: D_IH_S_EH_N_T\n",
      "Prediction: D_IH_S_EH_N_T\n",
      "200 / 500\n",
      "Word: ROACHE\n",
      "Transcription: R_OW_CH\n",
      "Prediction: R_OW_CH\n",
      "300 / 500\n",
      "Word: MERCHANTS\n",
      "Transcription: M_ER_CH_AH_N_T_S\n",
      "Prediction: M_ER_CH_AH_N_T_S\n",
      "400 / 500\n",
      "Word: ABBASI\n",
      "Transcription: AA_B_AA_S_IY\n",
      "Prediction: AE_B_AA_S_IY\n",
      "Prediction finished!!!\n",
      "Accuracy on train: 0.77\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy on train:\", get_accuracy(x_train[:500], y_train[:500]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 194\n",
      "Word: SAMANTHA\n",
      "Transcription: S_AH_M_AE_N_TH_AH\n",
      "Prediction: S_AH_M_AE_N_TH_AH\n",
      "100 / 194\n",
      "Word: DISDAINED\n",
      "Transcription: D_IH_S_D_EY_N_D\n",
      "Prediction: D_IH_S_D_EY_N_D\n",
      "Prediction finished!!!\n",
      "Accuracy on test: 0.6855670103092784\n"
     ]
    }
   ],
   "source": [
    "x_test = x_train_copy[83000:]\n",
    "y_test = y_train_copy[83000:]\n",
    "print(\"Accuracy on test:\", get_accuracy(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'emb_training_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-7cbe38f392e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mchar_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0memb_training_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mplot_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchar_embedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchar_to_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'emb_training_model' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_embeddings(embeddings, symbols, perplexity):\n",
    "    embeddings_in_2D = TSNE(n_components=2,perplexity=perplexity).fit_transform(embeddings)\n",
    "    embeddings_in_2D[:,0] = embeddings_in_2D[:,0] / np.max(np.abs(embeddings_in_2D[:,0]))\n",
    "    embeddings_in_2D[:,1] = embeddings_in_2D[:,1] / np.max(np.abs(embeddings_in_2D[:,1]))\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.set_size_inches(6,6)\n",
    "    ax.scatter(embeddings_in_2D[:,0], embeddings_in_2D[:,1],c='w')\n",
    "\n",
    "    for i, letter in enumerate(symbols):\n",
    "        ax.annotate(letter, (embeddings_in_2D[i,0],embeddings_in_2D[i,1]), fontsize=12, fontweight='bold')\n",
    "        \n",
    "        \n",
    "char_embedding = emb_training_model.layers[2].get_weights()[0]\n",
    "plot_embeddings(char_embedding, char_to_id.keys(), 5)\n",
    "\n",
    "phone_embedding = emb_training_model.layers[3].get_weights()[0]\n",
    "plot_embeddings(phone_embedding, phone_to_id.keys(), 18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1268"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"/home/pavel/MyDocs/MachineLearning/Yandex_ML_project/lecture4/Kaggle_phonetics/test.csv\")\n",
    "x_test = list(test_data['Word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_seqs = []\n",
    "    \n",
    "for word in x_test:\n",
    "    word_matrix = np.zeros((MAX_CHAR_SEQ_LEN))\n",
    "    for t, char in enumerate(word):\n",
    "        word_matrix[t] = char_to_id[char]\n",
    "    char_seqs.append(word_matrix)\n",
    "\n",
    "char_seq_matrix_test = np.array(char_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41597\n",
      "(41597, 34)\n"
     ]
    }
   ],
   "source": [
    "print(len(char_seq_matrix_test))\n",
    "print(char_seq_matrix_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_beamsearch(input_char_seq, encoder, decoder, k=3):\n",
    "    a = encoder.predict(input_char_seq) \n",
    "    \n",
    "    s = np.zeros((emb_char_input_train.shape[0], 256))\n",
    "    c = np.zeros((emb_char_input_train.shape[0], 256))\n",
    "    \n",
    "    all_seqs = []\n",
    "    all_seq_scores = []\n",
    "    \n",
    "    live_seqs = [[phone_to_id[START_PHONE_SYM]]]\n",
    "    live_scores = [0]\n",
    "    live_states = [[s,c]]\n",
    "\n",
    "    while len(live_seqs) > 0: \n",
    "        new_live_seqs = [] \n",
    "        new_live_scores = [] \n",
    "        new_live_states = []\n",
    "        \n",
    "        for sidx,seq in enumerate(live_seqs):\n",
    "            target_seq = np.array([[seq[-1]]])\n",
    "            output_token_probs, s, c = decoder.predict([target_seq] + live_states[sidx] + [a])\n",
    "            \n",
    "            best_token_indicies = output_token_probs[0,:].argsort()[-k:]\n",
    "\n",
    "            for token_index in best_token_indicies:\n",
    "                new_seq = seq + [token_index]\n",
    "                prob = output_token_probs[0,:][token_index]\n",
    "                new_seq_score = live_scores[sidx] - np.log(prob)\n",
    "                if id_to_phone[token_index] == END_PHONE_SYM or len(new_seq) > MAX_PHONE_SEQ_LEN:\n",
    "                    all_seqs.append(new_seq) \n",
    "                    all_seq_scores.append(new_seq_score) \n",
    "                    continue\n",
    "                new_live_seqs.append(new_seq)\n",
    "                new_live_scores.append(new_seq_score)\n",
    "                new_live_states.append([s, c])\n",
    "                \n",
    "        while len(new_live_scores) > k:\n",
    "            worst_seq_score_idx = np.array(new_live_scores).argsort()[-1] \n",
    "            del new_live_seqs[worst_seq_score_idx]\n",
    "            del new_live_scores[worst_seq_score_idx]\n",
    "            del new_live_states[worst_seq_score_idx]\n",
    "            \n",
    "        live_seqs = new_live_seqs\n",
    "        live_scores = new_live_scores\n",
    "        live_states = new_live_states\n",
    "        \n",
    "    best_idx = np.argmin(all_seq_scores)\n",
    "\n",
    "    pronunciation = ''\n",
    "    for i in all_seqs[best_idx]:\n",
    "        pronunciation += id_to_phone[i] + '_'\n",
    "    return pronunciation[2:-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 41597\n",
      "100 / 41597\n",
      "200 / 41597\n",
      "300 / 41597\n",
      "400 / 41597\n",
      "500 / 41597\n",
      "600 / 41597\n",
      "700 / 41597\n",
      "800 / 41597\n",
      "900 / 41597\n",
      "1000 / 41597\n",
      "1100 / 41597\n",
      "1200 / 41597\n",
      "1300 / 41597\n",
      "1400 / 41597\n",
      "1500 / 41597\n",
      "1600 / 41597\n",
      "1700 / 41597\n",
      "1800 / 41597\n",
      "1900 / 41597\n",
      "2000 / 41597\n",
      "2100 / 41597\n",
      "2200 / 41597\n",
      "2300 / 41597\n",
      "2400 / 41597\n",
      "2500 / 41597\n",
      "2600 / 41597\n",
      "2700 / 41597\n",
      "2800 / 41597\n",
      "2900 / 41597\n",
      "3000 / 41597\n",
      "3100 / 41597\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-e11942c292bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchar_seq_matrix_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mexample_char_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchar_seq_matrix_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mpredicted_pronun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_beamsearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample_char_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_testing_encoder_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_testing_decoder_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-36-462268f48dc3>\u001b[0m in \u001b[0;36mpredict_beamsearch\u001b[0;34m(input_char_seq, encoder, decoder, k)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msidx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlive_seqs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mtarget_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0moutput_token_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_seq\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlive_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msidx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mbest_token_indicies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_token_probs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1170\u001b[0m                                             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1172\u001b[0;31m                                             steps=steps)\n\u001b[0m\u001b[1;32m   1173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1174\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m    295\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                 \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2659\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2661\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2662\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2663\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2629\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2630\u001b[0m                                 session)\n\u001b[0;32m-> 2631\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2632\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "y_test = []\n",
    "for i in range(len(char_seq_matrix_test)):\n",
    "    example_char_seq = char_seq_matrix_test[i:i+1]\n",
    "    predicted_pronun = predict_beamsearch(example_char_seq, attn_testing_encoder_model, attn_testing_decoder_model)\n",
    "        \n",
    "    if i % 100 == 0:\n",
    "        print(i, '/', len(char_seq_matrix_test))\n",
    "            \n",
    "    y_test.append(predicted_pronun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PITCHED', 'DISSOLVERS', 'SCRAWNY', 'BONENFANT', 'EXCEEDS', 'BARTNICKI', 'BUTE', 'CAPITULATE', 'STEAM', 'INVESTCORP']\n",
      "['P_IH_CH_T', 'D_IH_S_AA_L_V_ER_Z', 'S_K_R_AO_N_IY', 'B_OW_N_AH_N_F_AH_N_T', 'IH_K_S_IY_D_Z', 'B_AA_R_T_N_IH_T_S_K_IY', 'B_Y_UW_T', 'K_AH_P_IH_CH_AH_L_EY_T', 'S_T_IY_M', 'IH_N_V_EH_S_T_K_AO_R_P']\n"
     ]
    }
   ],
   "source": [
    "print(x_test[:10])\n",
    "print(y_test[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv(\"/home/pavel/MyDocs/MachineLearning/Yandex_ML_project/lecture4/Kaggle_phonetics/test.csv\")\n",
    "submission['Word'] = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Id                  Word\n",
      "0   1             P_IH_CH_T\n",
      "1   2    D_IH_S_AA_L_V_ER_Z\n",
      "2   3         S_K_R_AO_N_IY\n",
      "3   4  B_OW_N_AH_N_F_AH_N_T\n",
      "4   5         IH_K_S_IY_D_Z\n"
     ]
    }
   ],
   "source": [
    "print(submission.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Id                         Word\n",
      "41592  41593  IH_N_AA_K_Y_AH_L_EY_SH_AH_N\n",
      "41593  41594                    AH_N_T_UW\n",
      "41594  41595                S_K_OW_G_IH_N\n",
      "41595  41596                HH_EH_SH_AH_N\n",
      "41596  41597           T_ER_N_AO_F_S_K_IY\n"
     ]
    }
   ],
   "source": [
    "print(submission.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"/home/pavel/MyDocs/MachineLearning/Yandex_ML_project/lecture4/Kaggle_phonetics/submission_baseline_model2_attention.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Model\n",
      "--------------------\n",
      "Perfect Accuracy: 0.0%\n",
      "Bleu Score: 0.3248\n"
     ]
    }
   ],
   "source": [
    "perfect_acc, avg_bleu_score = evaluate(\n",
    "    char_input_test, testing_encoder_model, testing_decoder_model, one_hot_matrix_to_word, predict_baseline)\n",
    "print_results('Baseline Model',perfect_acc, avg_bleu_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
